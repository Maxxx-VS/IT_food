# import gradio as gr
# from gradio_imageslider import ImageSlider
# from loadimg import load_img
# import spaces
# from transformers import AutoModelForImageSegmentation
# import torch
# from torchvision import transforms
#
# torch.set_float32_matmul_precision(["high", "highest"][0])
#
# birefnet = AutoModelForImageSegmentation.from_pretrained(
#     "ZhengPeng7/BiRefNet", trust_remote_code=True
# )
# birefnet.to("cpu") # –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ birefnet.to("cuda")
#
# transform_image = transforms.Compose(
#     [
#         transforms.Resize((1024, 1024)),
#         transforms.ToTensor(),
#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
#     ]
# )
#
# def fn(image):
#     im = load_img(image, output_type="pil")
#     im = im.convert("RGB")
#     origin = im.copy()
#     processed_image = process(im)
#     return (processed_image, origin)
#
# @spaces.GPU
# def process(image):
#     image_size = image.size
#     input_images = transform_image(image).unsqueeze(0).to("cuda")
#     # Prediction
#     with torch.no_grad():
#         preds = birefnet(input_images)[-1].sigmoid().cpu()
#     pred = preds[0].squeeze()
#     pred_pil = transforms.ToPILImage()(pred)
#     mask = pred_pil.resize(image_size)
#     image.putalpha(mask)
#     return image
#
# def process_file(f):
#     name_path = f.rsplit(".", 1)[0] + ".png"
#     im = load_img(f, output_type="pil")
#     im = im.convert("RGB")
#     transparent = process(im)
#     transparent.save(name_path)
#     return name_path
#
# slider1 = ImageSlider(label="Processed Image", type="pil")
# slider2 = ImageSlider(label="Processed Image from URL", type="pil")
# image_upload = gr.Image(label="Upload an image")
# image_file_upload = gr.Image(label="Upload an image", type="filepath")
# url_input = gr.Textbox(label="Paste an image URL")
# output_file = gr.File(label="Output PNG File")
#
# # Example images
# chameleon = load_img("butterfly.jpg", output_type="pil")
# url_example = "https://hips.hearstapps.com/hmg-prod/images/gettyimages-1229892983-square.jpg"
#
# tab1 = gr.Interface(fn, inputs=image_upload, outputs=slider1, examples=[chameleon], api_name="image")
# tab2 = gr.Interface(fn, inputs=url_input, outputs=slider2, examples=[url_example], api_name="text")
# tab3 = gr.Interface(process_file, inputs=image_file_upload, outputs=output_file, examples=["butterfly.jpg"], api_name="png")
#
# demo = gr.TabbedInterface(
#     [tab1, tab2, tab3], ["Image Upload", "URL Input", "File Output"], title="Background Removal Tool"
# )
#
#
# if __name__ == "__main__":
#     demo.launch(show_error=True)

import gradio as gr
from gradio_imageslider import ImageSlider
from PIL import Image
import requests
from io import BytesIO
import os
from transformers import AutoModelForImageSegmentation
import torch
from torchvision import transforms

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã –Ω–∞ CPU
torch.set_float32_matmul_precision("high")
device = "cpu"  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
birefnet = AutoModelForImageSegmentation.from_pretrained(
    "ZhengPeng7/BiRefNet",
    trust_remote_code=True
).to(device)

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
transform_image = transforms.Compose([
    transforms.Resize((1024, 1024)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
])


def load_img(path, output_type="pil"):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ URL"""
    if path.startswith(("http://", "https://")):
        response = requests.get(path)
        img = Image.open(BytesIO(response.content))
    else:
        img = Image.open(path)

    if output_type == "pil":
        return img
    elif output_type == "numpy":
        return np.array(img)
    else:
        raise ValueError("output_type must be 'pil' or 'numpy'")


def process(image):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —É–¥–∞–ª–µ–Ω–∏–µ —Ñ–æ–Ω–∞"""
    image_size = image.size
    input_images = transform_image(image).unsqueeze(0).to(device)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏
    with torch.no_grad():
        preds = birefnet(input_images)[-1].sigmoid().cpu()

    pred = preds[0].squeeze()
    pred_pil = transforms.ToPILImage()(pred)
    mask = pred_pil.resize(image_size)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ñ–æ–Ω–æ–º
    result = image.copy()
    result.putalpha(mask)

    return result


def process_and_save(input_image, output_dir="results"):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    os.makedirs(output_dir, exist_ok=True)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if isinstance(input_image, str):
        if input_image.startswith(("http://", "https://")):
            img = load_img(input_image)
            filename = f"web_image_{hash(input_image)}.png"
        else:
            img = Image.open(input_image)
            filename = os.path.basename(input_image).rsplit('.', 1)[0] + ".png"
    else:
        img = input_image
        filename = f"processed_{hash(str(input_image))}.png"

    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    result = process(img)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    output_path = os.path.join(output_dir, filename)
    result.save(output_path, "PNG")

    return result, output_path


def process_upload(image):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    img = load_img(image.name)
    processed, saved_path = process_and_save(img)
    return (processed, img, saved_path)


def process_url(url):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ URL"""
    img = load_img(url)
    processed, saved_path = process_and_save(img)
    return (processed, img, saved_path)


# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
with gr.Blocks(title="Background Removal Tool") as demo:
    gr.Markdown("# üñºÔ∏è –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞")
    gr.Markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ URL –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–æ–Ω–∞")

    with gr.Tabs():
        with gr.Tab("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"):
            with gr.Row():
                image_input = gr.UploadButton("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type="filepath")
            with gr.Row():
                original_image = gr.Image(label="–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", interactive=False)
                result_image = gr.Image(label="–†–µ–∑—É–ª—å—Ç–∞—Ç", interactive=False)
            save_info = gr.Textbox(label="–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤", interactive=False)

            image_input.upload(
                process_upload,
                inputs=[image_input],
                outputs=[result_image, original_image, save_info]
            )

        with gr.Tab("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ URL"):
            with gr.Row():
                url_input = gr.Textbox(label="URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", placeholder="https://example.com/image.jpg")
                url_submit = gr.Button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å")
            with gr.Row():
                url_original = gr.Image(label="–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", interactive=False)
                url_result = gr.Image(label="–†–µ–∑—É–ª—å—Ç–∞—Ç", interactive=False)
            url_save_info = gr.Textbox(label="–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤", interactive=False)

            url_submit.click(
                process_url,
                inputs=[url_input],
                outputs=[url_result, url_original, url_save_info]
            )

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True
    )